{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We will build the Skipgram and CBOW models from scratch, train them on a relatively small corpus, i.e, on BBC Data set."
      ],
      "metadata": {
        "id": "5MyJGHC1BaWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkdi2YQiz3Fc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import operator\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Reshape, Lambda\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors as nn\n",
        "from matplotlib import pylab\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/bbc-text.csv')\n",
        "print(df)\n",
        "sentences = ''\n",
        "articles = list(df['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMNFODiS2UXU",
        "outputId": "ec961276-90fb-4068-8b02-a80595e18ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           category                                               text\n",
            "0              tech  tv future in the hands of viewers with home th...\n",
            "1          business  worldcom boss  left books alone  former worldc...\n",
            "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
            "3             sport  yeading face newcastle in fa cup premiership s...\n",
            "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
            "...             ...                                                ...\n",
            "2220       business  cars pull down us retail figures us retail sal...\n",
            "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
            "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
            "2223       politics  how political squabbles snowball it s become c...\n",
            "2224          sport  souness delight at euro progress boss graeme s...\n",
            "\n",
            "[2225 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skip Gram"
      ],
      "metadata": {
        "id": "krCIiau6BNVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for i in articles[:80]:\n",
        "    sentences += i.split('.')\n",
        "\n",
        "# Remove sentences with fewer than 3 words\n",
        "corpus = [sentence for sentence in sentences if sentence.count(\" \") >= 2]\n",
        "\n",
        "# Remove punctuation in text and fit tokenizer on entire corpus\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n'+\"'\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# Convert text to sequence of integer values\n",
        "corpus = tokenizer.texts_to_sequences(corpus)\n",
        "n_samples = sum(len(s) for s in corpus) # Total number of words in the corpus\n",
        "V = len(tokenizer.word_index) + 1 # Total number of unique words in the corpus"
      ],
      "metadata": {
        "id": "zUsTuWeG9_Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab53f306-679f-4433-9d2c-ebde4019cdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 101 ms, sys: 1.59 ms, total: 103 ms\n",
            "Wall time: 112 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkpMdk0W_Tvb",
        "outputId": "4c2c197a-f628-48c0-8901-4d0b29291776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29158, 5368)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how word to integer mapping looks like in the tokenizer\n",
        "print(list((tokenizer.word_index.items()))[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8H_KWQi_Vg-",
        "outputId": "833df2c8-b5e8-4dcf-e4ed-a8d90dadcdd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 1), ('to', 2), ('of', 3), ('a', 4), ('and', 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Parameters\n",
        "window_size = 2\n",
        "window_size_corpus = 4\n",
        "\n",
        "# Set numpy seed for reproducible results\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "49Vrpesb_X5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare data for the skipgram model\n",
        "def generate_data_skipgram(corpus, window_size, V):\n",
        "    maxlen = window_size * 2\n",
        "    all_in = []\n",
        "    all_out = []\n",
        "    for words in corpus:\n",
        "        L = len(words)\n",
        "        for index, word in enumerate(words):\n",
        "            p = index - window_size\n",
        "            n = index + window_size + 1\n",
        "\n",
        "            in_words = []\n",
        "            labels = []\n",
        "            for i in range(p, n):\n",
        "                if i != index and 0 <= i < L:\n",
        "                    # Add the input word\n",
        "                    all_in.append(word)\n",
        "                    # Add one-hot of the context words\n",
        "                    all_out.append(to_categorical(words[i], V))\n",
        "\n",
        "    return (np.array(all_in), np.array(all_out))"
      ],
      "metadata": {
        "id": "9Yh1m9sn_auh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Create training data\n",
        "X_skip, y_skip = generate_data_skipgram(corpus, window_size, V)\n",
        "X_skip.shape, y_skip.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0dDFx_a_b9q",
        "outputId": "1e6c28a7-92e0-45c8-da6f-a387442c798c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.22 s, sys: 1.43 s, total: 2.64 s\n",
            "Wall time: 2.65 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108016,), (108016, 5368))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Create skipgram architecture\n",
        "\n",
        "dim = 100\n",
        "skipgram_models = []\n",
        "\n",
        "# Initialize a Keras Sequential model\n",
        "skipgram = Sequential()\n",
        "\n",
        "# Add an Embedding layer\n",
        "skipgram.add(Embedding(input_dim=V,\n",
        "                        output_dim=dim,\n",
        "                        input_length=1,\n",
        "                        embeddings_initializer='glorot_uniform'))\n",
        "\n",
        "# Add a Reshape layer, which reshapes the output of the embedding layer (1,dim) to (dim,)\n",
        "skipgram.add(Reshape((dim, )))\n",
        "\n",
        "# Add a final Dense layer with the same size as in [1]\n",
        "skipgram.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n",
        "\n",
        "# Compile the model with a suitable loss function and select an optimizer.\n",
        "# Optimizer Adagrad was used in paper\n",
        "skipgram.compile(optimizer=keras.optimizers.Adam(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "skipgram.summary()\n",
        "print(\"\")\n",
        "skipgram_models.append(skipgram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFII7Bz5_dXp",
        "outputId": "7f259f84-16d0-478d-ea81-513030053201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 100)            536800    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5368)              542168    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1078968 (4.12 MB)\n",
            "Trainable params: 1078968 (4.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "CPU times: user 646 ms, sys: 235 ms, total: 881 ms\n",
            "Wall time: 2.73 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# Training the skipgram models\n",
        "for skipgram in skipgram_models:\n",
        "    skipgram.fit(X_skip, y_skip, batch_size=64, epochs=15, verbose=1)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWouhLLB_gpb",
        "outputId": "cd5d19fb-ec11-43db-b5ae-6b54ebd4699b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1688/1688 [==============================] - 18s 8ms/step - loss: 7.3907 - accuracy: 0.0608\n",
            "Epoch 2/15\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 6.8333 - accuracy: 0.0676\n",
            "Epoch 3/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 6.6881 - accuracy: 0.0731\n",
            "Epoch 4/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 6.5259 - accuracy: 0.0803\n",
            "Epoch 5/15\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 6.3414 - accuracy: 0.0890\n",
            "Epoch 6/15\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 6.1425 - accuracy: 0.0963\n",
            "Epoch 7/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 5.9399 - accuracy: 0.1005\n",
            "Epoch 8/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 5.7434 - accuracy: 0.1023\n",
            "Epoch 9/15\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 5.5585 - accuracy: 0.1032\n",
            "Epoch 10/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 5.3885 - accuracy: 0.1023\n",
            "Epoch 11/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 5.2353 - accuracy: 0.1016\n",
            "Epoch 12/15\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 5.0973 - accuracy: 0.0999\n",
            "Epoch 13/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 4.9759 - accuracy: 0.0979\n",
            "Epoch 14/15\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 4.8707 - accuracy: 0.0961\n",
            "Epoch 15/15\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 4.7800 - accuracy: 0.0933\n",
            "\n",
            "CPU times: user 2min 12s, sys: 15.5 s, total: 2min 28s\n",
            "Wall time: 3min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for skipgram in skipgram_models:\n",
        "    weights = skipgram.get_weights()\n",
        "\n",
        "    # Get the embedding matrix\n",
        "    embedding = weights[0]\n",
        "\n",
        "    # Get word embeddings for each word in the vocabulary, write to file\n",
        "    f = open(f\"vectors_skipgram_{len(embedding[0])}.txt\", \"w\")\n",
        "\n",
        "    # Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n",
        "    columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n",
        "\n",
        "    # Start writing to the file, start with the column names\n",
        "    f.write(\" \".join(columns))\n",
        "\n",
        "    # Start a new line\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        f.write(word)\n",
        "        f.write(\" \")\n",
        "        f.write(\" \".join(map(str, list(embedding[i,:]))))\n",
        "        f.write(\"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "cldfl4HP_jAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram.get_weights()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5nkl5mF_n1H",
        "outputId": "49fb8b3c-bb4f-4bdf-ce40-69d0c7f0d470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0280514 ,  0.00633277, -0.0297009 , ..., -0.01276754,\n",
              "        -0.00261297,  0.01973111],\n",
              "       [ 0.2016724 , -0.34099865,  0.06056718, ...,  0.05937553,\n",
              "         0.6281242 ,  0.2644408 ],\n",
              "       [-0.59093523, -0.08562579,  0.26864326, ...,  0.1961121 ,\n",
              "        -0.18560983,  0.04168729],\n",
              "       ...,\n",
              "       [-0.3091724 ,  0.20727606,  0.13891563, ..., -0.49539888,\n",
              "        -0.28663093,  0.19539887],\n",
              "       [ 0.27804348, -0.03453066, -0.06964883, ..., -0.13181476,\n",
              "         0.06794297, -0.14912298],\n",
              "       [-0.08548996, -0.12734386,  0.01529881, ..., -0.12156113,\n",
              "         0.501686  ,  0.36864257]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(skipgram.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MMXBpKICNld",
        "outputId": "ce6cd34f-663b-4f15-8aa0-4bebcfb255c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(skipgram.get_weights()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM00BJo8CZgf",
        "outputId": "8cbd7a1c-0421-4050-ae0f-544fe618bf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5368"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(skipgram.get_weights()[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx6NU83WCaL1",
        "outputId": "5b43df0d-91d2-4a6e-ebb6-3f6f52f679e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram.get_weights()[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwHlFJ4VCc7J",
        "outputId": "9a3cb9e1-9019-4079-a70c-05d37c504790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.2016724 , -0.34099865,  0.06056718, -0.02997063, -0.2095625 ,\n",
              "       -0.10585789,  0.12256892,  0.16617462,  0.3222422 , -0.23193647,\n",
              "       -0.19682544, -0.02064507,  0.14807023,  0.23470451,  0.10948326,\n",
              "       -0.25430372,  0.21665928,  0.3309034 , -0.21474394, -0.17216541,\n",
              "        0.1988407 ,  0.2989586 , -0.31570372,  0.1974094 ,  0.32606086,\n",
              "        0.24848923, -0.0194772 ,  0.33561116, -0.17210004, -0.16591637,\n",
              "       -0.18304642, -0.01622173, -0.18109913,  0.05863833,  0.07199619,\n",
              "        0.22383435, -0.09396132,  0.2805166 , -0.2570826 ,  0.19285458,\n",
              "       -0.01536875, -0.3160898 ,  0.09866587, -0.03627656, -0.09316628,\n",
              "        0.21988797,  0.04269576, -0.08087586, -0.29026258,  0.06641474,\n",
              "        0.07396381,  0.1643963 ,  0.4445107 , -0.46609503,  0.2517619 ,\n",
              "       -0.32623035,  0.2524388 ,  0.5811687 , -0.0214692 , -0.14889832,\n",
              "        0.04396792, -0.23036313, -0.20201139,  0.00559659, -0.25663364,\n",
              "        0.16170435,  0.2641098 , -0.11385378,  0.07858003,  0.07819052,\n",
              "       -0.24721006,  0.0153313 , -0.18063785, -0.32192776,  0.02163422,\n",
              "       -0.2858523 ,  0.13125637, -0.1021739 ,  1.2819972 ,  0.11334942,\n",
              "       -0.34465268,  0.09503108,  0.08274169,  0.0622605 , -0.16248347,\n",
              "        0.2435074 , -0.19979973, -0.24382466,  0.32030654, -0.2134292 ,\n",
              "       -0.5589139 ,  0.13361001,  0.3113441 , -0.14859292,  0.26467726,\n",
              "        0.11761256, -0.05243009,  0.05937553,  0.6281242 ,  0.2644408 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the word embedding:"
      ],
      "metadata": {
        "id": "WndM_dgtBsB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = tokenizer.word_index['king']"
      ],
      "metadata": {
        "id": "stGNMknWCga3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram.get_weights()[0][index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQIeSU9YCqLk",
        "outputId": "4a373eca-8710-42b4-ff22-836d1410c637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.3329974 , -0.34593946,  0.21893133, -0.00926998,  0.5448755 ,\n",
              "       -0.25804842, -0.31043002,  0.5402896 ,  0.18649508,  0.19944073,\n",
              "       -0.125581  , -0.20627189, -0.37291726, -0.06565852, -0.20601559,\n",
              "       -0.36603346,  0.21348958, -0.00171248, -0.09430709, -0.09572998,\n",
              "        0.32611454,  0.24519673, -0.16359042,  0.12024733, -0.26432282,\n",
              "       -0.34060258, -0.07175371,  0.69065845, -0.32866818, -0.04020369,\n",
              "        0.32348067, -0.74996585,  0.23313628, -0.4581679 ,  0.07766113,\n",
              "        0.05767743, -0.04669981, -0.29721177,  0.6522683 , -0.04243769,\n",
              "       -0.5192642 ,  0.36859947,  0.21754432, -0.03036747,  0.41784155,\n",
              "       -0.17789076,  0.53237957, -0.66123646,  0.18967815,  0.33967313,\n",
              "       -0.18866128,  0.15688777, -0.16077752, -0.44108018, -0.2192727 ,\n",
              "        0.22307149,  0.33844784, -0.11983999, -0.03577344, -0.16427666,\n",
              "        0.5541761 , -0.2896473 , -0.49448028,  0.21642114, -0.40521762,\n",
              "       -0.71553487, -0.5385699 , -0.29812378, -0.15177771, -0.59099036,\n",
              "       -0.18080884, -0.01747493,  0.46787307, -0.41028637,  0.5064141 ,\n",
              "       -0.03256192,  0.49203777, -0.29077983,  0.01148029,  0.04085233,\n",
              "       -0.08035376,  0.31598458,  0.6829478 ,  0.22850603, -0.0985605 ,\n",
              "       -0.04394713,  0.10857796, -0.4796327 , -0.26004228,  0.22866039,\n",
              "        0.31828788, -0.16158031,  0.20633645,  0.06936862,  0.14152431,\n",
              "       -0.15798146,  0.06107296,  0.30718264, -0.31694034,  0.07788437],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load your pre-trained word embeddings into a dictionary or a matrix\n",
        "# word_vectors should be a dictionary where keys are words and values are their corresponding vectors\n",
        "# Or word_vectors can be a matrix where rows correspond to words and columns are vector dimensions\n",
        "# You should replace this with your actual word embeddings\n",
        "\n",
        "# Sample code for loading pre-trained word vectors into a dictionary\n",
        "word_vectors = {}\n",
        "i=0\n",
        "\n",
        "target_word = \"prince\"\n",
        "\n",
        "\n",
        "with open(\"/content/vectors_skipgram_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        i+=1\n",
        "        if i == 1:\n",
        "            continue\n",
        "        parts = line.strip().split()\n",
        "        word = parts[0]\n",
        "        vector = np.array([float(x) for x in parts[1:]])\n",
        "        word_vectors[word] = vector\n",
        "\n",
        "# Target word for which you want to find the k-nearest words\n",
        "\n",
        "\n",
        "# Calculate cosine similarities with all words in the vocabulary\n",
        "similarities = {}\n",
        "target_vector = word_vectors[target_word]\n",
        "for word, vector in word_vectors.items():\n",
        "    if word != target_word:\n",
        "        cosine_sim = cosine_similarity([target_vector], [vector])\n",
        "        similarities[word] = cosine_sim[0][0]\n",
        "\n",
        "# Sort the words by their cosine similarity scores in descending order\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Select the top-k words as the k-nearest words\n",
        "k = 10  # Number of nearest words you want to find\n",
        "nearest_words = [word for word, _ in sorted_similarities[:k]]\n",
        "\n",
        "# Print the k-nearest words\n",
        "print(f\"The {k} nearest words to '{target_word}' are: \")\n",
        "for i in (nearest_words):\n",
        "    print(i)\n",
        "\n",
        "\n",
        "skipgram_word_emd = word_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52erh42yFVzA",
        "outputId": "1eeff8c0-1d6c-4695-ce67-e4dd1663fe2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 10 nearest words to 'prince' are: \n",
            "grandson\n",
            "kennedy\n",
            "princes\n",
            "camilla\n",
            "mood\n",
            "charles\n",
            "rowntree\n",
            "ros\n",
            "becomes\n",
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CBOW"
      ],
      "metadata": {
        "id": "tVkTnQHpBC9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Prepare the data for the CBOW model\n",
        "def generate_data_cbow(corpus, window_size, V):\n",
        "    all_in = []\n",
        "    all_out = []\n",
        "\n",
        "    # Iterate over all sentences\n",
        "    for sentence in corpus:\n",
        "        L = len(sentence)\n",
        "        for index, word in enumerate(sentence):\n",
        "            start = index - window_size\n",
        "            end = index + window_size + 1\n",
        "\n",
        "            # Empty list which will store the context words\n",
        "            context_words = []\n",
        "            for i in range(start, end):\n",
        "                # Skip the 'same' word\n",
        "                if i != index:\n",
        "                    # Add a word as a context word if it is within the window size\n",
        "                    if 0 <= i < L:\n",
        "                        context_words.append(sentence[i])\n",
        "                    else:\n",
        "                        # Pad with zero if there are no words\n",
        "                        context_words.append(0)\n",
        "            # Append the list with context words\n",
        "            all_in.append(context_words)\n",
        "\n",
        "            # Add one-hot encoding of the target word\n",
        "            all_out.append(to_categorical(word, V))\n",
        "\n",
        "    return (np.array(all_in), np.array(all_out))"
      ],
      "metadata": {
        "id": "mjFSAz4xM0Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# Create the training data\n",
        "X_cbow, y_cbow = generate_data_cbow(corpus, window_size, V)\n",
        "X_cbow.shape, y_cbow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an4kfPrHM4BV",
        "outputId": "d15512dc-14b3-433c-b0cf-fd9bccd21187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 548 ms, sys: 63.6 ms, total: 612 ms\n",
            "Wall time: 615 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((29158, 4), (29158, 5368))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Create the CBOW architecture\n",
        "cbow_models = []\n",
        "dim = 100\n",
        "cbow = Sequential()\n",
        "\n",
        "# Add an Embedding layer\n",
        "cbow.add(Embedding(input_dim=V,\n",
        "                    output_dim=dim,\n",
        "                    input_length=window_size*2, # Note that we now have 2L words for each input entry\n",
        "                    embeddings_initializer='glorot_uniform'))\n",
        "\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim, )))\n",
        "\n",
        "cbow.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n",
        "\n",
        "cbow.compile(optimizer=keras.optimizers.Adam(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "cbow.summary()\n",
        "print(\"\")\n",
        "cbow_models.append(cbow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJBnZ-lAM7o0",
        "outputId": "92d444e1-5881-4366-9149-4a131da799fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 4, 100)            536800    \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5368)              542168    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1078968 (4.12 MB)\n",
            "Trainable params: 1078968 (4.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "CPU times: user 257 ms, sys: 91.6 ms, total: 349 ms\n",
            "Wall time: 364 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Train CBOW model\n",
        "for cbow in cbow_models:\n",
        "    cbow.fit(X_cbow, y_cbow, batch_size=64, epochs=50, verbose=1)\n",
        "    print(\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZywPe5gyM-O6",
        "outputId": "79407da9-26e5-42eb-d9ef-edd56d630f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "456/456 [==============================] - 11s 23ms/step - loss: 7.7740 - accuracy: 0.0605\n",
            "Epoch 2/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 6.9844 - accuracy: 0.0633\n",
            "Epoch 3/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 6.7899 - accuracy: 0.0742\n",
            "Epoch 4/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 6.6404 - accuracy: 0.0821\n",
            "Epoch 5/50\n",
            "456/456 [==============================] - 4s 8ms/step - loss: 6.5019 - accuracy: 0.0872\n",
            "Epoch 6/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 6.3596 - accuracy: 0.0922\n",
            "Epoch 7/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 6.2076 - accuracy: 0.0993\n",
            "Epoch 8/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 6.0447 - accuracy: 0.1117\n",
            "Epoch 9/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 5.8721 - accuracy: 0.1247\n",
            "Epoch 10/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 5.6892 - accuracy: 0.1373\n",
            "Epoch 11/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 5.4997 - accuracy: 0.1499\n",
            "Epoch 12/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 5.3065 - accuracy: 0.1630\n",
            "Epoch 13/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 5.1116 - accuracy: 0.1787\n",
            "Epoch 14/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 4.9165 - accuracy: 0.1954\n",
            "Epoch 15/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 4.7222 - accuracy: 0.2131\n",
            "Epoch 16/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 4.5296 - accuracy: 0.2321\n",
            "Epoch 17/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 4.3392 - accuracy: 0.2504\n",
            "Epoch 18/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 4.1518 - accuracy: 0.2721\n",
            "Epoch 19/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 3.9689 - accuracy: 0.2933\n",
            "Epoch 20/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 3.7904 - accuracy: 0.3165\n",
            "Epoch 21/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 3.6159 - accuracy: 0.3370\n",
            "Epoch 22/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 3.4469 - accuracy: 0.3609\n",
            "Epoch 23/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 3.2828 - accuracy: 0.3853\n",
            "Epoch 24/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 3.1238 - accuracy: 0.4084\n",
            "Epoch 25/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 2.9695 - accuracy: 0.4330\n",
            "Epoch 26/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 2.8206 - accuracy: 0.4572\n",
            "Epoch 27/50\n",
            "456/456 [==============================] - 3s 5ms/step - loss: 2.6763 - accuracy: 0.4822\n",
            "Epoch 28/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 2.5374 - accuracy: 0.5086\n",
            "Epoch 29/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 2.4037 - accuracy: 0.5328\n",
            "Epoch 30/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 2.2753 - accuracy: 0.5580\n",
            "Epoch 31/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 2.1522 - accuracy: 0.5822\n",
            "Epoch 32/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 2.0347 - accuracy: 0.6055\n",
            "Epoch 33/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.9226 - accuracy: 0.6278\n",
            "Epoch 34/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.8153 - accuracy: 0.6491\n",
            "Epoch 35/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 1.7134 - accuracy: 0.6695\n",
            "Epoch 36/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.6171 - accuracy: 0.6893\n",
            "Epoch 37/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.5255 - accuracy: 0.7080\n",
            "Epoch 38/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.4384 - accuracy: 0.7259\n",
            "Epoch 39/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.3569 - accuracy: 0.7430\n",
            "Epoch 40/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 1.2792 - accuracy: 0.7579\n",
            "Epoch 41/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.2064 - accuracy: 0.7742\n",
            "Epoch 42/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.1373 - accuracy: 0.7877\n",
            "Epoch 43/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.0732 - accuracy: 0.8017\n",
            "Epoch 44/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 1.0119 - accuracy: 0.8126\n",
            "Epoch 45/50\n",
            "456/456 [==============================] - 4s 8ms/step - loss: 0.9546 - accuracy: 0.8242\n",
            "Epoch 46/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 0.9009 - accuracy: 0.8340\n",
            "Epoch 47/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 0.8508 - accuracy: 0.8441\n",
            "Epoch 48/50\n",
            "456/456 [==============================] - 2s 5ms/step - loss: 0.8034 - accuracy: 0.8543\n",
            "Epoch 49/50\n",
            "456/456 [==============================] - 3s 6ms/step - loss: 0.7589 - accuracy: 0.8626\n",
            "Epoch 50/50\n",
            "456/456 [==============================] - 3s 7ms/step - loss: 0.7173 - accuracy: 0.8707\n",
            "\n",
            "CPU times: user 2min 10s, sys: 12.6 s, total: 2min 23s\n",
            "Wall time: 3min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for cbow in cbow_models:\n",
        "    weights = cbow.get_weights()\n",
        "\n",
        "    # Get the embedding matrix\n",
        "    embedding = weights[0]\n",
        "\n",
        "    # Get word embeddings for each word in the vocabulary, write to file\n",
        "    f = open(f'vectors_cbow_{len(embedding[0])}.txt', 'w')\n",
        "\n",
        "    # Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n",
        "    columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n",
        "\n",
        "    # Start writing to the file, start with the column names\n",
        "    f.write(\" \".join(columns))\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        f.write(word)\n",
        "        f.write(\" \")\n",
        "        f.write(\" \".join(map(str, list(embedding[i,:]))))\n",
        "        f.write(\"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "tIzwSyBRNC-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Loading pre-trained word embeddings into a dictionary or a matrix\n",
        "# word_vectors should be a dictionary where keys are words and values are their corresponding vectors\n",
        "# Or word_vectors can be a matrix where rows correspond to words and columns are vector dimensions\n",
        "\n",
        "\n",
        "\n",
        "word_vectors = {}\n",
        "i=0\n",
        "\n",
        "target_word = \"king\"\n",
        "\n",
        "\n",
        "with open(\"/content/vectors_cbow_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        i+=1\n",
        "        if i == 1:\n",
        "            continue\n",
        "        parts = line.strip().split()\n",
        "        word = parts[0]\n",
        "        vector = np.array([float(x) for x in parts[1:]])\n",
        "        word_vectors[word] = vector\n",
        "\n",
        "# Target word for which you want to find the k-nearest words\n",
        "\n",
        "\n",
        "# Calculate cosine similarities with all words in the vocabulary\n",
        "similarities = {}\n",
        "target_vector = word_vectors[target_word]\n",
        "for word, vector in word_vectors.items():\n",
        "    if word != target_word:\n",
        "        cosine_sim = cosine_similarity([target_vector], [vector])\n",
        "        similarities[word] = cosine_sim[0][0]\n",
        "\n",
        "# Sort the words by their cosine similarity scores in descending order\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Select the top-k words as the k-nearest words\n",
        "k = 10  # Number of nearest words you want to find\n",
        "nearest_words = [word for word, _ in sorted_similarities[:k]]\n",
        "\n",
        "# Print the k-nearest words\n",
        "print(f\"The {k} nearest words to '{target_word}' are: \")\n",
        "for i in (nearest_words):\n",
        "    print(i)\n",
        "\n",
        "\n",
        "cbow_word_emd = word_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOduYv-ENJU8",
        "outputId": "3e552262-dc2f-4709-a44d-9a9b038e5ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 10 nearest words to 'king' are: \n",
            "thin\n",
            "restructuing\n",
            "cream\n",
            "mallorcan\n",
            "becomes\n",
            "violence\n",
            "became\n",
            "dance\n",
            "bundled\n",
            "baskin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the word embedding:"
      ],
      "metadata": {
        "id": "W0TRjJt_BzEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(skipgram_word_emd),len(cbow_word_emd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD90GjaOB14b",
        "outputId": "4159efc7-0a65-4f36-b9af-e512272a6b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5367, 5367)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_word_emd['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq0PcAvlC3Rj",
        "outputId": "1728bc19-2d1d-4299-95bd-00a606ac30d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.3329974 , -0.34593946,  0.21893133, -0.00926998,  0.5448755 ,\n",
              "       -0.25804842, -0.31043002,  0.5402896 ,  0.18649508,  0.19944073,\n",
              "       -0.125581  , -0.20627189, -0.37291726, -0.06565852, -0.20601559,\n",
              "       -0.36603346,  0.21348958, -0.00171248, -0.09430709, -0.09572998,\n",
              "        0.32611454,  0.24519673, -0.16359042,  0.12024733, -0.26432282,\n",
              "       -0.34060258, -0.07175371,  0.69065845, -0.32866818, -0.04020369,\n",
              "        0.32348067, -0.74996585,  0.23313628, -0.4581679 ,  0.07766113,\n",
              "        0.05767743, -0.04669981, -0.29721177,  0.6522683 , -0.04243769,\n",
              "       -0.5192642 ,  0.36859947,  0.21754432, -0.03036747,  0.41784155,\n",
              "       -0.17789076,  0.53237957, -0.66123646,  0.18967815,  0.33967313,\n",
              "       -0.18866128,  0.15688777, -0.16077752, -0.44108018, -0.2192727 ,\n",
              "        0.22307149,  0.33844784, -0.11983999, -0.03577344, -0.16427666,\n",
              "        0.5541761 , -0.2896473 , -0.49448028,  0.21642114, -0.40521762,\n",
              "       -0.71553487, -0.5385699 , -0.29812378, -0.15177771, -0.59099036,\n",
              "       -0.18080884, -0.01747493,  0.46787307, -0.41028637,  0.5064141 ,\n",
              "       -0.03256192,  0.49203777, -0.29077983,  0.01148029,  0.04085233,\n",
              "       -0.08035376,  0.31598458,  0.6829478 ,  0.22850603, -0.0985605 ,\n",
              "       -0.04394713,  0.10857796, -0.4796327 , -0.26004228,  0.22866039,\n",
              "        0.31828788, -0.16158031,  0.20633645,  0.06936862,  0.14152431,\n",
              "       -0.15798146,  0.06107296,  0.30718264, -0.31694034,  0.07788437])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_word_emd['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6mIdxkoDAcd",
        "outputId": "13f0f72b-932e-492e-b37c-3bef85dd3ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.40849736,  0.83842176,  0.76997   , -0.22403689,  1.1738381 ,\n",
              "       -1.195571  , -0.5294099 , -0.2563375 ,  1.004601  , -1.2284474 ,\n",
              "       -0.14232187,  0.10904235,  0.5015107 ,  0.48668098, -0.18598354,\n",
              "        0.9957963 ,  0.04341465, -1.0003383 , -0.52898973,  0.16919012,\n",
              "        1.0728117 ,  0.04841719, -1.6397748 ,  0.57037044,  0.4790564 ,\n",
              "        0.20876846, -0.05828866, -0.49795058, -0.32566577,  0.6376983 ,\n",
              "       -0.23290294,  0.05514616,  1.9663172 ,  0.3662006 ,  0.4217175 ,\n",
              "       -1.1287767 ,  1.1819786 ,  0.06207106,  0.4526754 , -0.12408181,\n",
              "       -0.80580086,  0.460728  , -0.72695285, -1.025451  ,  1.1780716 ,\n",
              "        1.0432673 ,  0.10634957, -0.766422  ,  0.39446223, -0.3177677 ,\n",
              "        0.6336937 , -0.51412696, -0.26367947, -0.17996639,  0.46548152,\n",
              "        0.75701135, -0.02343865, -0.45402536,  0.34043965,  0.8864516 ,\n",
              "       -0.4046189 ,  0.58849335, -1.1570829 ,  0.6935536 ,  0.23517364,\n",
              "       -0.5019113 ,  0.6715626 ,  0.22422247,  0.61462957,  1.2924591 ,\n",
              "       -1.0302551 ,  1.1397837 ,  0.29741678,  1.2057813 , -0.25954774,\n",
              "        1.1556342 , -1.0848066 , -1.007588  , -0.07176077, -0.6294464 ,\n",
              "        0.698466  ,  0.09122873, -0.41145563, -0.2442107 , -0.61237377,\n",
              "       -1.37101   , -0.35901624,  1.6783603 ,  0.41192117, -0.01300054,\n",
              "        0.15341213, -0.33876216,  0.4381474 ,  0.40590394, -0.35111952,\n",
              "        0.28621304, -0.290971  ,  0.22579575,  0.8622856 , -0.5130493 ])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity([skipgram_word_emd['king']], [skipgram_word_emd['queen']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WqqC9hlDtgs",
        "outputId": "4cd7e2a0-aa9a-454e-9e9c-52cbd7fa4c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35694565]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity([cbow_word_emd['king']], [cbow_word_emd['queen']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn76dASUD4FT",
        "outputId": "2b03bf38-e50e-4e09-c99d-2041b330aa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32032359]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "-0G_eKAIYlR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvoDUWS5Yqgp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}